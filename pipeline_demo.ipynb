{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b1364f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appearance adjustment\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a977f8fc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from simulator import simulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5625f4db",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define - Dataset, Model, calc_acc, dataset_creation, Sim Params Class, RMSELoss\n",
    "    \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, samples, labels):\n",
    "        \n",
    "        super(Dataset, self).__init__()\n",
    "\n",
    "        self.dataset = []\n",
    "        \n",
    "        for sample, label in zip(samples, labels):\n",
    "            self.dataset.append((torch.tensor(sample).float(), torch.tensor(label).float()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "                                        \n",
    "        return self.dataset[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(nn.Linear(num_in, 32),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(32, 64),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(64, 64),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(64, num_out),\n",
    "                                     nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    \n",
    "    \n",
    "# def calculate_accuracy(all_preds, all_labels):\n",
    "\n",
    "#     accuracy = 0\n",
    "#     for i, (pred, label) in enumerate(zip(all_preds, all_labels)):\n",
    "        \n",
    "#         pred = np.argmax(pred)\n",
    "        \n",
    "#         if(pred == label):\n",
    "#             accuracy = accuracy + 1\n",
    "    \n",
    "#     return accuracy / (i + 1)\n",
    "\n",
    "\n",
    "\n",
    "def ballsINTObins(m, n):\n",
    "\n",
    "    if m==0:\n",
    "        return np.zeros((1, n))\n",
    "    \n",
    "    if n==1:\n",
    "        return np.asarray([m])\n",
    "    \n",
    "    all_rest = []\n",
    "    for i in range(m+1):\n",
    "        rest = ballsINTObins(m-i, n-1)\n",
    "        all_rest.append(np.c_[np.ones(rest.shape[0])*i, rest])\n",
    "    \n",
    "    result = np.concatenate(all_rest, axis=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self, air_trans_file, air_RI, atm_dist_ratio, basis_func_file,\n",
    "                 num_substances, spectra_file, substances_emit_file):\n",
    "        self.air_trans_file = air_trans_file\n",
    "        self.air_RI = air_RI\n",
    "        self.atm_dist_ratio = atm_dist_ratio\n",
    "        self.basis_func_file = basis_func_file\n",
    "        self.num_substances = num_substances\n",
    "        self.spectra_file = spectra_file\n",
    "        self.substances_emit_file = substances_emit_file\n",
    "        \n",
    "        \n",
    "        \n",
    "def RMSELoss(predict, target):\n",
    "    return torch.sqrt(torch.mean((predict-target)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4387132",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Epochs definition\n",
    "\n",
    "def train_epoch(model, device, dataloader, criterions, optimizer):\n",
    "    # Support for nultiple criterion functions - MSE for training and others for error display.\n",
    "    train_loss = [0 for criterion in criterions]\n",
    "    model.train()\n",
    "    \n",
    "    for samples, labels in dataloader:\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(samples)\n",
    "        \n",
    "        # Training criterion is the last in the list, so that the loss could be used directly for back prop.\n",
    "        for i, criterion in enumerate(criterions):\n",
    "            loss = criterion(output, labels)\n",
    "            train_loss[i] += loss.item() * samples.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return np.asarray(train_loss)\n",
    "\n",
    "\n",
    "\n",
    "def valid_epoch(model, device, dataloader, criterions):\n",
    "    valid_loss = [0 for criterion in criterions]\n",
    "    model.eval()\n",
    "    \n",
    "    for samples, labels in dataloader:\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        \n",
    "        output = model(samples)\n",
    "        \n",
    "        for i, criterion in enumerate(criterions):\n",
    "            loss = criterion(output, labels)\n",
    "            valid_loss[i] += loss.item() * samples.size(0)\n",
    "        \n",
    "    return np.asarray(valid_loss)\n",
    "\n",
    "\n",
    "\n",
    "def test_epoch(model, device, dataloader, criterions):\n",
    "    test_loss = [0 for criterion in criterions]\n",
    "    pred_list = []\n",
    "    targ_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for samples, labels in dataloader:\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        \n",
    "        output = model(samples)\n",
    "        \n",
    "        pred_list.append(output.detach().numpy())\n",
    "        targ_list.append(labels.detach().numpy())\n",
    "        \n",
    "        for i, criterion in enumerate(criterions):\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss[i] += loss.item()\n",
    "            \n",
    "    return np.asarray(test_loss), pred_list, targ_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b33ec51",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "   \n",
    "sim_params = Parameters(air_trans_file='./data/Test 2 - 21 Substances/Air transmittance.xlsx',\n",
    "                        air_RI=1,\n",
    "                        atm_dist_ratio=0.11,\n",
    "                        basis_func_file='./data/Test 2 - 21 Substances/Basis functions.xlsx',\n",
    "                        num_substances=4,\n",
    "                        spectra_file='./data/Test 2 - 21 Substances/spectra.xlsx',\n",
    "                        substances_emit_file='./data/Test 2 - 21 Substances/substances.xlsx')\n",
    "\n",
    "\n",
    "# Enviroment related parameters\n",
    "temp_K = 293.15 # Environmental temperature in K\n",
    "air_trans = np.array(pd.read_excel(sim_params.air_trans_file, header=None))\n",
    "air_trans = air_trans[:, 1:]\n",
    "atm_dist_ratio = sim_params.atm_dist_ratio # Atomsphere distance ratio\n",
    "air_RI = sim_params.air_RI # Refractive index of air\n",
    "\n",
    "# Sensor related parameters\n",
    "basis_funcs = np.array(pd.read_excel(sim_params.basis_func_file, header=None))\n",
    "basis_funcs = basis_funcs[:, 1:]\n",
    "\n",
    "# Substance related parameters\n",
    "num_substances = sim_params.num_substances\n",
    "spectra = np.array(pd.read_excel(sim_params.spectra_file, header=None))\n",
    "substances_emit = np.array(pd.read_excel(sim_params.substances_emit_file, header=None))\n",
    "substances_emit = substances_emit[:, 0:sim_params.num_substances]\n",
    "# Material mixture proportion\n",
    "mat_proportion = ballsINTObins(10, sim_params.num_substances).transpose() / 10\n",
    "# mat_proportion = np.array(pd.read_excel('./data/Test 2 - 21 Substances/proportion_NN_test.xlsx', header=None))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(mat_proportion.shape[1]):\n",
    "    weights = mat_proportion[:, i]\n",
    "    mat_em = np.average(substances_emit, weights=weights, axis=1)\n",
    "    mat_em = np.expand_dims(mat_em, 1)\n",
    "    out = simulator(spectra, mat_em, temp_K, air_trans, atm_dist_ratio, air_RI, basis_funcs)\n",
    "    data.append(out)\n",
    "    labels.append(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d7e4c6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "\n",
    "dataset = Dataset(data, labels)\n",
    "\n",
    "batch_size = len(data) // 10\n",
    "\n",
    "train_percentage = 0.8\n",
    "train_size = int(train_percentage * len(data))\n",
    "test_size = len(dataset) - train_size\n",
    "torch.manual_seed(28)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "criterions = [nn.L1Loss(), RMSELoss, nn.MSELoss()]\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65a4ccf",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07092e25e804a90948a376b42dca6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350dfddb57e64a03a2c4aa21e90cc196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ca9c6be6a243599a3a7797363fda2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82d575f4af4420980b030612bad7220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d10df9704e7426a90fe84f067e861fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train - k fold\n",
    "\n",
    "history = []\n",
    "models = []\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f'\\nFOLD {fold + 1}')\n",
    "#     print('--------------------------------')\n",
    "    train_subsampler = SubsetRandomSampler(train_ids)\n",
    "    valid_subsampler = SubsetRandomSampler(valid_ids)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "    valid_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=valid_subsampler)\n",
    "    \n",
    "    model = MLP(num_in=basis_funcs.shape[1], num_out=sim_params.num_substances)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model_loss_records = {'train_loss': [], 'valid_loss': []}\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = train_epoch(model, device, train_loader, criterions, optimizer)\n",
    "        valid_loss = valid_epoch(model, device, valid_loader, criterions)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        valid_loss = valid_loss / len(valid_loader.sampler)\n",
    "        \n",
    "        model_loss_records['train_loss'].append(train_loss)\n",
    "        model_loss_records['valid_loss'].append(valid_loss)\n",
    "        \n",
    "    model_loss_records['train_loss'] = np.asarray(model_loss_records['train_loss'])\n",
    "    model_loss_records['valid_loss'] = np.asarray(model_loss_records['valid_loss'])\n",
    "    history.append(model_loss_records)\n",
    "    models.append(model)\n",
    "        \n",
    "#         print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Valid Loss:{:.3f} \".format(epoch + 1,\n",
    "#                                                                                    num_epochs,\n",
    "#                                                                                    train_loss,\n",
    "#                                                                                    valid_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81682f2c",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7f5cc20ca142158e7215fbdcc58aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base line\n",
    "\n",
    "epoch = 1000\n",
    "\n",
    "MSE = []\n",
    "avg_MSE = []\n",
    "RMSE = []\n",
    "avg_RMSE = []\n",
    "L1Loss = []\n",
    "avg_L1Loss = []\n",
    "\n",
    "\n",
    "mseloss = nn.MSELoss()\n",
    "l1loss = nn.L1Loss()\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    \n",
    "    target_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    pred_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    pred_loader_iter = iter(pred_loader)\n",
    "\n",
    "    for x, target in target_loader:\n",
    "\n",
    "        xx, pred = next(pred_loader_iter)\n",
    "\n",
    "        MSE.append(mseloss(pred, target).item())\n",
    "        RMSE.append(RMSELoss(pred, target).item())\n",
    "        L1Loss.append(l1loss(pred, target).item())\n",
    "        \n",
    "    avg_MSE.append(np.mean(MSE))\n",
    "    avg_RMSE.append(np.mean(RMSE))\n",
    "    avg_L1Loss.append(np.mean(L1Loss))\n",
    "\n",
    "print(avg_MSE[-1])\n",
    "print(avg_RMSE[-1])\n",
    "print(avg_L1Loss[-1])\n",
    "\n",
    "plt.plot(avg_MSE)\n",
    "plt.plot(avg_RMSE)\n",
    "plt.plot(avg_L1Loss)\n",
    "\n",
    "plt.legend(['avg_MSE', 'avg_RMSE', 'avg_L1Loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d106c",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot k fold\n",
    "fig, axs = plt.subplots(5, figsize=(12, 16))\n",
    "fig.tight_layout(pad=5)\n",
    "# np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "loss = []\n",
    "loss_func_index = 1\n",
    "base_line_loss = [avg_L1Loss[-1], avg_RMSE[-1], avg_MSE[-1]]\n",
    "# avg_loss = 0\n",
    "for i in range (5):\n",
    "    axs[i].plot(history[i]['train_loss'][:, loss_func_index])\n",
    "    axs[i].plot(history[i]['valid_loss'][:, loss_func_index])\n",
    "    axs[i].axhline(base_line_loss[loss_func_index], color='r')\n",
    "    \n",
    "    axs[i].set_xlabel('Epoch')\n",
    "    axs[i].set_ylabel('MSE')\n",
    "    \n",
    "    axs[i].legend(['train loss', 'valid loss', 'base line'], \n",
    "                  title=f'Last Loss: {\"{:0.3e}\".format(history[i][\"valid_loss\"][:, loss_func_index][-1])}')\n",
    "    \n",
    "    axs[i].set_title('Fold' + str(i))\n",
    "    \n",
    "    loss.append(history[i][\"valid_loss\"][:, loss_func_index][-1])\n",
    "    \n",
    "    \n",
    "#     avg_loss += history[i][\"valid_loss\"][-1]\n",
    "    \n",
    "avg_loss = np.mean(loss)\n",
    "best_loss = np.min(loss)\n",
    "best_model_index = np.argmin(loss)\n",
    "\n",
    "print(\"avg loss =\", avg_loss)\n",
    "print(\"best loss =\", best_loss)\n",
    "print(\"best model index =\", best_model_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31286c3",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot k fold test result\n",
    "\n",
    "model = models[best_model_index]\n",
    "test_loss, pred_list, targ_list = test_epoch(model, device, test_loader, criterions)\n",
    "\n",
    "loss_func_index = 1\n",
    "base_line_loss = [avg_L1Loss[-1], avg_RMSE[-1], avg_MSE[-1]]\n",
    "\n",
    "test_loss = test_loss / len(test_dataset)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.plot(history[best_model_index]['train_loss'][:, loss_func_index])\n",
    "ax.plot(history[best_model_index]['valid_loss'][:, loss_func_index])\n",
    "# colors = ['r', 'g', 'y']\n",
    "# for loss, c in zip(test_loss, colors):\n",
    "ax.axhline(y=loss[loss_func_index], color='g')\n",
    "    \n",
    "# ax.plot(avg_RMSE)\n",
    "# ax.plot(avg_L1Loss)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend(['train loss', 'valid loss', 'test loss'], \n",
    "          title=f'Last Loss: {\"{:0.3e}\".format(history[best_model_index][\"valid_loss\"][:, loss_func_index][-1])}')\n",
    "\n",
    "for i in range(10):\n",
    "    print('Target: ', targ_list[i])\n",
    "    print('Predict:', pred_list[i], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c425d01e3fe884931333939e0ad7960b908645cf1ab99418b036767927303f60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
